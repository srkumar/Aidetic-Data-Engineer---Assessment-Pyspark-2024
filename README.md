# Aidetic-Data-Engineer---Assessment-Pyspark-2024
**Assignment based on Pyspark**

**Tasks:**

1. Load the dataset into a PySpark DataFrame.
2. Convert the Date and Time columns into a timestamp column named Timestamp.
3. Filter the dataset to include only earthquakes with a magnitude greater than 5.0.
4. Calculate the average depth and magnitude of earthquakes for each earthquake type.
5. Implement a UDF to categorize the earthquakes into levels (e.g., Low, Moderate, High) based on their magnitudes.
6. Calculate the distance of each earthquake from a reference location (e.g., (0, 0)).
7. Visualize the geographical distribution of earthquakes on a world map using appropriate libraries (e.g., Basemap or Folium).
8. Please include the final csv in the repository.

**Dataset Definition:**
1. Use the earthquake dataset with the following columns:
2. Date (string): Date of the earthquake.
3. Time (string): Time of the earthquake.
4. Latitude (float): Latitude of the earthquake location.
5. Longitude (float): Longitude of the earthquake location.
6. Type (string): Type of earthquake.
7. Depth (float): Depth of the earthquake.
8. Magnitude (float): Magnitude of the earthquake.

